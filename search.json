[{"path":"/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program’s commands might different; GUI interface, use “box”. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU GPL, see <http://www.gnu.org/licenses/>. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read <http://www.gnu.org/philosophy/--lgpl.html>.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. <program>  Copyright (C) <year>  <name of author> This program comes with ABSOLUTELY NO WARRANTY; for details type 'show w'. This is free software, and you are welcome to redistribute it under certain conditions; type 'show c' for details."},{"path":"/articles/downsampling.html","id":"working-example","dir":"Articles","previous_headings":"","what":"Working Example","title":"Downsampling for Predictive Modeling","text":"Programme International Student Assessment (PISA) international study conducted Organisation Economic Co-operation Development (OECD) every three years. assesses 15-year-old students mathematics, science, reading collecting information students schools. pisa dataset included medley package comes 2009 administration used demonstrate predicting private versus public school attendance. 5,233 observations across 44 variables 93.4% public school students 6.6% private school students. begin, split data training validation set using splitstackshape::stratified() function ensure ratio public--private school students datasets. can estimate logistic regression model get predicted probabilities validation dataset. figure shows distribution predicted probabilities validation dataset. separation public private school students, densities clearly centered right side range.  figure provides receiver operator characteristic (ROC) curve along plot accuracy, sensitivity, specificity.  confusion matrix , splitting 0.5, indicates model better null model (.e percent public school students 93.4%). course adjust cut value optimize either specificity sensitivity.","code":"library(medley) data('pisa', package = 'medley') data('pisa_variables', package = 'medley') pisa_formu <- Public ~ . names(pisa) <- pisa_variables[names(pisa)] pisa_splits <- splitstackshape::stratified(     pisa, group = \"Public\", size = 0.75, bothSets = TRUE) pisa_train <- pisa_splits[[1]] |> as.data.frame() pisa_valid <- pisa_splits[[2]] |> as.data.frame() table(pisa$Public, useNA = 'ifany') |> print() |> prop.table() #>  #> FALSE  TRUE  #>   345  4888 #>  #>      FALSE       TRUE  #> 0.06592777 0.93407223 table(pisa_train$Public, useNA = 'ifany') |> print() |> prop.table() #>  #> FALSE  TRUE  #>   259  3666 #>  #>      FALSE       TRUE  #> 0.06598726 0.93401274 table(pisa_valid$Public, useNA = 'ifany') |> print() |> prop.table() #>  #> FALSE  TRUE  #>    86  1222 #>  #>      FALSE       TRUE  #> 0.06574924 0.93425076 pisa_lr_out <- glm(pisa_formu, data = pisa_train, family = binomial(link = 'logit')) pisa_predictions <- predict(pisa_lr_out, newdata = pisa_valid, type = 'response') ggplot(data.frame(Public = pisa_valid$Public,                    Prediction = pisa_predictions),         aes(x = Prediction, color = Public)) +   geom_density() calculate_roc(predictions = pisa_predictions,                observed = pisa_valid$Public) |> plot() confusion_matrix(observed = pisa_valid$Public,                   predicted = pisa_predictions > 0.5) #>            predicted               #>   observed     FALSE          TRUE #>      FALSE 1 (0.08%)    85 (6.50%) #>       TRUE 4 (0.31%) 1218 (93.12%) #> Accuracy: 93.2% #> Sensitivity: 1.16% #> Specificity: 99.67%"},{"path":"/articles/downsampling.html","id":"shrinking-fitted-values","dir":"Articles","previous_headings":"","what":"Shrinking Fitted Values","title":"Downsampling for Predictive Modeling","text":"turns range fitted values logistic regression shrink amount imbalance dependent variable increases. first encountered issue estimating propensity scores dissertation study charter versus traditional public school students. study using National Assessment Educational Progress (NAEP) approximately 3% students attended charter school. study, range propensity scores severely constrained. explore , multilevel::psrange() function developed result function figure . Starting bottom, 345 public school students randomly selected logistic regression estimated perfect balance dependent variable. move increase ratio 1:1 1:13. ratio, 20 random samples drawn, logistic regression model estimated, minimum maximum fitted values (.e. predicted probabilities) recorded (represented black dots green bars). distributions across models also included.  Plotting just ranges along mean fitted values public (blue) private (green) school students shows ratio greater 3--1 mean fitted values zero class (private schools example) greater 0.5.","code":""},{"path":"/articles/downsampling.html","id":"downsampling","dir":"Articles","previous_headings":"","what":"Downsampling","title":"Downsampling for Predictive Modeling","text":"discussed one key disadvantages downsampling situations significant imbalance excluding lot data analysis. downsample() function first determine many models need estimated observation larger class used exactly . example using public--private student ratio 2--1 model estimated 259 private 518 public student observations. Given 3925 observations training set, dowmsample() function estimate 7 models. can use predict() function get data frame predictions. column corresponds predicted value 7 models. can average predictions get single vector. density distributions provided . distributions like distributions expect balanced data even though use observations get predicted probabilities.  Although downsample() function appears address issue shrinking centered fitted values, model performance metrics provided suggest improve overall performance model predictions.","code":"pisa_ds_out <- downsample(   formu = pisa_formu,   data = pisa_train,   model_fun = glm,   ratio = 2,   family = binomial(link = 'logit'),   show_progress = FALSE) length(pisa_ds_out) #> [1] 7 pisa_predictions_ds <- predict(pisa_ds_out,                                newdata = pisa_valid,                                 type = 'response') head(pisa_predictions_ds) #>      model1    model2    model3    model4    model5    model6    model7 #> 1 0.8511828 0.7437341 0.8921605 0.8424369 0.7347052 0.8697531 0.6928875 #> 2 0.7393116 0.6822714 0.9466815 0.7959953 0.8118642 0.9441840 0.9580830 #> 3 0.4944206 0.3813138 0.5575741 0.3586561 0.5023435 0.5805062 0.6281852 #> 4 0.8525691 0.8268514 0.8293386 0.8372777 0.9464037 0.8843848 0.9016058 #> 5 0.1823382 0.3670335 0.4556063 0.1408078 0.1899378 0.3578418 0.2657968 #> 6 0.9216160 0.8192096 0.9040353 0.9213184 0.8080822 0.9076342 0.8768295 pisa_predictions_ds2 <- pisa_predictions_ds |> apply(1, mean) ggplot(data.frame(Public = pisa_valid$Public,                    Prediction = pisa_predictions_ds2),         aes(x = Prediction, color = Public)) +   geom_density() roc <- calculate_roc(predictions = pisa_predictions_ds2,                       observed = pisa_valid$Public) plot(roc) confusion_matrix(observed = pisa_valid$Public,                   predicted = pisa_predictions_ds2 > 0.5) #>               predicted               #>   observed        FALSE          TRUE #>      FALSE   45 (3.44%)    41 (3.13%) #>       TRUE 204 (15.60%) 1018 (77.83%) #> Accuracy: 81.27% #> Sensitivity: 52.33% #> Specificity: 83.31%"},{"path":"/articles/downsampling.html","id":"appendix-a-model-summaries","dir":"Articles","previous_headings":"","what":"Appendix A: Model Summaries","title":"Downsampling for Predictive Modeling","text":"averaged predicted values across models get single prediction observation validation dataset. However, possible pool models using mice::pool() function get single set regression coefficients. table provides pooled regression coefficients downsample function along coefficients logistic regression model using data.","code":""},{"path":"/articles/downsampling.html","id":"appendix-b-random-forest","dir":"Articles","previous_headings":"","what":"Appendix B: Random Forest","title":"Downsampling for Predictive Modeling","text":"downsample() function can use nearly modeling function available R. appendix show use random forest. order use classification randomForest() must convert dependent varaible factor. Setting model_fun = randomForest estimate random forest models models. Random forest returns predicted class type = 'response'. several ways can handle . use simple voting strategy.","code":"library(randomForest) data('pisa', package = 'medley') data('pisa_variables', package = 'medley') pisa$Public <- factor(pisa$Public) pisa_splits <- splitstackshape::stratified(     pisa, group = \"Public\", size = 0.75, bothSets = TRUE) pisa_train <- pisa_splits[[1]] |> as.data.frame() pisa_valid <- pisa_splits[[2]] |> as.data.frame() pisa_ds_out_rf <- downsample(   formu = pisa_formu,   data = pisa_train,   model_fun = randomForest,   ratio = 2,   show_progress = FALSE) length(pisa_ds_out_rf) #> [1] 7  pisa_predictions_ds_rf <- predict(pisa_ds_out_rf,                                   newdata = pisa_valid,                                    type = 'response') head(pisa_predictions_ds_rf) #>   model1 model2 model3 model4 model5 model6 model7 #> 1   TRUE   TRUE   TRUE   TRUE   TRUE   TRUE   TRUE #> 2  FALSE   TRUE   TRUE   TRUE   TRUE   TRUE   TRUE #> 3   TRUE   TRUE  FALSE   TRUE   TRUE   TRUE   TRUE #> 4  FALSE   TRUE  FALSE  FALSE  FALSE  FALSE   TRUE #> 5   TRUE   TRUE   TRUE   TRUE   TRUE   TRUE   TRUE #> 6  FALSE  FALSE   TRUE  FALSE  FALSE  FALSE  FALSE pisa_predictions_ds_rf_vote <- apply(     pisa_predictions_ds_rf, 1,      FUN = function(x) { mean(as.logical(x)) > 0.5}) confusion_matrix(observed = pisa_valid$Public,                   predicted = pisa_predictions_ds_rf_vote) #>               predicted               #>   observed        FALSE          TRUE #>      FALSE   37 (2.83%)    49 (3.75%) #>       TRUE 143 (10.93%) 1079 (82.49%) #> Accuracy: 85.32% #> Sensitivity: 43.02% #> Specificity: 88.3%"},{"path":"/articles/medley.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"medley: Predictive Modeling with Missing Data","text":"predictive modeling strategies require complete data train predict outcomes. common strategy impute missing data training models. However, many situations, missing data occurs systematic way therefore violating missing completely random (MCAR) assumption. instance, data may collected multiple time periods available data may vary depending varying collection protocols selection bias individual level. medley package provides framework estimating predictive model takes account patterns missing data. motivating example approach predictive modeling comes predicting student success college. Institutions become increasingly interested using predictive models identify students risk attrition early possible order provided targeted interventions supports. Information students collected several months beginning college application phase, commitment enroll, orientation, finally behavior data student begins coursework. addition missing data related student process, students may opt provide certain data elements. results complex system single predictive model appropriate.","code":""},{"path":"/articles/medley.html","id":"data-source","dir":"Articles","previous_headings":"","what":"Data Source","title":"medley: Predictive Modeling with Missing Data","text":"paper explore data Diagnostic Assessment Achievement College Skills (DAACS; https://daacs.net). DAACS suite technological social supports designed optimize student learning. Students complete assessments self-regulated learning, writing, mathematics, reading upon completion receive immediate feedback terms developing, emerging, mastering. feedback tailored results. data paper part larger randomized control trial DAACS embedded within orientation treatment students. Although students instructed orientation required, consequences completing orientation therefore approximately 43% students attempt orientation, therefore complete DAACS. goal predicted term--term retention (retained variable) student based upon available data. Table @ref(tab:descriptives) descriptive statistics reveals DAACS results complete students. overall retention rate 56.17%. Descriptive Statistics","code":""},{"path":"/articles/medley.html","id":"missing-data-patterns","dir":"Articles","previous_headings":"Data Source","what":"Missing Data Patterns","title":"medley: Predictive Modeling with Missing Data","text":"begin first explore patterns missing data. Figure @ref(fig:upset) UpSet plot (Gu, Eils, Schlesner 2016) created shadow matrix1. vertical line corresponds set, combination, variables. dots indicate variable included set. bars top correspond number observations set bars right correspond total number observed values. largest set includes demographics variables, second largest included demographics DAACS variables. third set includes self-regulated learning along demographics worth considering since contains 10% observations. noted potential fourth set included demographic variables along three DAACS variables (SRL, reading, math). However, since set fewer 10% observations use three set/model solution. UpSet plot missing data","code":"shadow_matrix <- as.data.frame(!is.na(daacs)) ComplexHeatmap::make_comb_mat(shadow_matrix) |> ComplexHeatmap::UpSet(right_annotation = NULL)"},{"path":"/articles/medley.html","id":"data-preparation","dir":"Articles","previous_headings":"Data Source","what":"Data Preparation","title":"medley: Predictive Modeling with Missing Data","text":"perform predictive modeling split data training (70%) validation (30%) data sets.","code":"set.seed(2112); train_rows <- sample(nrow(daacs), nrow(daacs) * 0.7) daacs_train <- daacs[train_rows,] daacs_valid <- daacs[-train_rows,]"},{"path":"/articles/medley.html","id":"baseline-models","dir":"Articles","previous_headings":"","what":"Baseline Models","title":"medley: Predictive Modeling with Missing Data","text":"generally two choices estimating models missing data: 1) Model using available data 2) Impute missing data modeling.","code":""},{"path":"/articles/medley.html","id":"using-available-data","dir":"Articles","previous_headings":"Baseline Models","what":"Using available data","title":"medley: Predictive Modeling with Missing Data","text":"DAACS data set depicted Figure @ref(fig:upset) demographics variables observed students. start train logistic regression model training data. can get predicted values validation data set print confusion matrix. overall accuracy using demographic variables 61.09% Note random forests used type = 'response' provides predicted class. wish get predicted probabilities instead use type = 'prob' (also random forest returns two column predicted values, column 2 corresponds predicted probability “success” class). useful wish plot receiver operating characteristic (ROC) curve shown figure .","code":"lr_out <- glm(data = daacs_train,               formula = retained ~ income + employment + ell + ed_mother + ed_father +                 ethnicity + gender + military + age,               family = binomial(link = 'logit')) rf_out <- randomForest(formula = factor(retained) ~ income + employment + ell + ed_mother + ed_father +                          ethnicity + gender + military + age,                        data = daacs_train) lr_predictions <- predict(lr_out, newdata = daacs_valid, type = 'response') confusion_matrix(observed = daacs_valid$retained,                  predicted = lr_predictions > 0.5) #>               predicted              #>   observed        FALSE         TRUE #>      FALSE 295 (19.07%) 386 (24.95%) #>       TRUE 216 (13.96%) 650 (42.02%) #> Accuracy: 61.09% #> Sensitivity: 43.32% #> Specificity: 75.06%  rf_predictions <- predict(rf_out, newdata = daacs_valid, type = 'response') confusion_matrix(observed = daacs_valid$retained,                  predicted = rf_predictions) #>               predicted              #>   observed        FALSE         TRUE #>      FALSE 279 (18.03%) 402 (25.99%) #>       TRUE 251 (16.22%) 615 (39.75%) #> Accuracy: 57.79% #> Sensitivity: 40.97% #> Specificity: 71.02% calculate_roc(     predictions = predict(rf_out, newdata = daacs_valid, type = 'prob')[,2],     observed = daacs_valid$retained ) |> plot()"},{"path":"/articles/medley.html","id":"mean-imputation","dir":"Articles","previous_headings":"Baseline Models","what":"Mean Imputation","title":"medley: Predictive Modeling with Missing Data","text":"","code":"daacs_complete_mean <- daacs for(i in 2:ncol(daacs_complete_mean)) {     missing_rows <- is.na(daacs_complete_mean[,i])     if(sum(missing_rows) > 0) {         daacs_complete_mean[missing_rows, i] <- mean(daacs_complete_mean[,i], na.rm = TRUE)     } } daacs_train_complete_mean <- daacs_complete_mean[train_rows,] daacs_valid_complete_mean <- daacs_complete_mean[-train_rows,]  mean_lr_out <- glm(formula = retained ~ .,                    data = daacs_train_complete_mean,                    family = binomial(link = logit)) mean_lr_predictions <- predict(mean_lr_out, newdata = daacs_valid_complete_mean, type = 'response') confusion_matrix(observed = daacs_valid_complete_mean$retained,                  predicted = mean_lr_predictions > 0.5) #>               predicted              #>   observed        FALSE         TRUE #>      FALSE 292 (18.88%) 389 (25.15%) #>       TRUE 212 (13.70%) 654 (42.28%) #> Accuracy: 61.15% #> Sensitivity: 42.88% #> Specificity: 75.52%  mean_rf_out <- randomForest(formula = factor(retained) ~ .,                             data = daacs_train_complete_mean) mean_rf_predictions <- predict(mean_rf_out, newdata = daacs_valid_complete_mean, type = 'response') confusion_matrix(observed = daacs_valid_complete_mean$retained,                  predicted = mean_rf_predictions) #>               predicted              #>   observed        FALSE         TRUE #>      FALSE 316 (20.43%) 365 (23.59%) #>       TRUE 178 (11.51%) 688 (44.47%) #> Accuracy: 64.9% #> Sensitivity: 46.4% #> Specificity: 79.45%"},{"path":"/articles/medley.html","id":"multiple-imputation","dir":"Articles","previous_headings":"Baseline Models","what":"Multiple imputation","title":"medley: Predictive Modeling with Missing Data","text":"Another common approach modeling missing data multiple imputation. mice package (Multivariate Imputations Chained Equations) robust popular approach imputing missing data. simplicity use final imputed data set comparison2. missing DAACS data imputed can train logistic regression model using full data set. overall accuracy using imputed data set 61.41%","code":"mice_out <- mice::mice(daacs[,-1], M = 5, seed = 2112, printFlag = FALSE) daacs_complete_mice <- cbind(retained = daacs$retained, mice::complete(mice_out))  daacs_train_complete_mice <- daacs_complete_mice[train_rows,] daacs_valid_complete_mice <- daacs_complete_mice[-train_rows,] mice_lr_out <- glm(formula = retained ~ .,                    data = daacs_train_complete_mice,                    family = binomial(link = logit)) mice_lr_predictions <- predict(mice_lr_out, newdata = daacs_valid_complete_mice, type = 'response') confusion_matrix(observed = daacs_valid_complete_mice$retained,                  predicted = mice_lr_predictions > 0.5) #>               predicted              #>   observed        FALSE         TRUE #>      FALSE 297 (19.20%) 384 (24.82%) #>       TRUE 213 (13.77%) 653 (42.21%) #> Accuracy: 61.41% #> Sensitivity: 43.61% #> Specificity: 75.4%  mice_rf_out <- randomForest(formula = factor(retained) ~ .,                             data = daacs_train_complete_mice) mice_rf_predictions <- predict(mice_rf_out, newdata = daacs_valid_complete_mice, type = 'response') confusion_matrix(observed = daacs_valid_complete_mice$retained,                  predicted = mice_rf_predictions) #>               predicted              #>   observed        FALSE         TRUE #>      FALSE 278 (17.97%) 403 (26.05%) #>       TRUE 207 (13.38%) 659 (42.60%) #> Accuracy: 60.57% #> Sensitivity: 40.82% #> Specificity: 76.1%"},{"path":"/articles/medley.html","id":"medley-models","dir":"Articles","previous_headings":"","what":"Medley models","title":"medley: Predictive Modeling with Missing Data","text":"medley_train function implements step wise approach training models. data formula parameters specify data set full model (.e. possible predictor variables considered), similar modeling functions R. method parameter indicates model procedure used. example estimate logistic regression models. medley_train can take additional parameters need passed method function. Table @ref(tab:model-summaries) provides baseline retention rate model along number observations formula models. exploring specific modeling reveals pattern missing data predictive success. Students complete four DAACS assessments % likely retained students complete assessments. Baseline retention rate model object returned medley_train contains following elements: n_models - number models estimated. formulas - list formulas used model. models - list containing model output model. example contain results glm function call. data - full data set used train models. model_observations - data frame indicating models observation used . rows correspond rows data columns correspond model. default algorithm use sets least 10% total observations (see @ref(tab:model-summaries)). can adjusted using min_set_size parameter (see get_variable_sets() function). Optionally can specify models directly passing list formulas var_sets parameter. Table @ref(tab:modelresults) provides model summaries 3 models estimated. (#tab:modelresults) Logistic regression results S3 generic function predict implemented. Specifying newdata parameter give predictions validation data set. confusion matrix provided . overall accuracy medley model 61.086% 5.11% baseline, null, model.","code":"medley_lr_out <- medley_train(data = daacs_train,                               formula = retained ~ .,                               method = glm,                               family = binomial(link = logit)) medley_lr_predictions <- predict(medley_lr_out,                                  newdata = daacs_valid,                                  type = 'response') confusion_matrix(observed = daacs_valid$retained,                  predicted = medley_lr_predictions > 0.5) #>               predicted              #>   observed        FALSE         TRUE #>      FALSE 305 (19.72%) 376 (24.31%) #>       TRUE 175 (11.31%) 691 (44.67%) #> Accuracy: 64.38% #> Sensitivity: 44.79% #> Specificity: 79.79%"},{"path":"/articles/medley.html","id":"random-forests","dir":"Articles","previous_headings":"Medley models","what":"Random Forests","title":"medley: Predictive Modeling with Missing Data","text":"core functionality medley_train algorithm select appropriate model given available data. specific predictive model user. Fernandez-Delgado et al (2014) evaluated performance 179 classifiers across 121 data sets. results showed , general, random forest best performing model. begin, load randomForest pacakge convert dependent variable factor ensure classification (versus regression) model estimated. Training predicting except set method = randomForest. Lastly, confusion matrix gives overall accuracy. example though see random forest performs sligthly worse logistic regression.","code":"daacs_train$retained <- as.factor(daacs_train$retained) daacs_valid$retained <- as.factor(daacs_valid$retained) medley_rf_out <- medley_train(data = daacs_train,                               formula = retained ~ .,                               method = randomForest) medley_rf_predictions <- predict(medley_rf_out,                                   newdata = daacs_valid,                                  type = \"response\") confusion_matrix(observed = daacs_valid$retained,                  predicted = medley_rf_predictions ) #>            predicted              #>   observed     FALSE         TRUE #>      FALSE 0 (0.00%) 681 (44.02%) #>       TRUE 0 (0.00%) 866 (55.98%) #> Accuracy: 55.98% #> Sensitivity: 0% #> Specificity: 100%"},{"path":"/articles/medley.html","id":"using-observations-in-multiple-models","dir":"Articles","previous_headings":"Medley models","what":"Using observations in multiple models","title":"medley: Predictive Modeling with Missing Data","text":"default behavior medley_train algorithm observation used one model. However, particular example, complete demographic data students potentially use observations train model. exclusive_membership parameter allow observations used training models complete data. results show get modest increase overall accuracy. noted predictions estimated model uses variables observation.","code":"medley_rf_out2 <- medley_train(data = daacs_train,                               formula = retained ~ .,                               exclusive_membership = FALSE,                               method = randomForest) medley_rf_predictions2 <- predict(medley_rf_out2,                            newdata = daacs_valid,                           type = \"response\") confusion_matrix(observed = daacs_valid$retained,                  predicted = medley_rf_predictions2 ) #>            predicted              #>   observed     FALSE         TRUE #>      FALSE 0 (0.00%) 681 (44.02%) #>       TRUE 0 (0.00%) 866 (55.98%) #> Accuracy: 55.98% #> Sensitivity: 0% #> Specificity: 100%"},{"path":"/articles/medley.html","id":"discussion","dir":"Articles","previous_headings":"","what":"Discussion","title":"medley: Predictive Modeling with Missing Data","text":"Model performance summary Note: Improvement difference overall retention rate 56.17%.","code":"Predicted                                                         Model Observed        FALSE         TRUE Accuracy  Observed data only logistic regression    FALSE 295 (19.07%) 386 (24.95%)                                                      TRUE 216 (13.96%) 650 (42.02%)                                                                                       61.09%        Observed data only random forest    FALSE 279 (18.03%) 402 (25.99%)                                                      TRUE 251 (16.22%) 615 (39.75%)                                                                                       57.79%    Imputed data set logistic regression    FALSE 297 (19.20%) 384 (24.82%)                                                      TRUE 213 (13.77%) 653 (42.21%)                                                                                       61.41%          Imputed data set random forest    FALSE 278 (17.97%) 403 (26.05%)                                                      TRUE 207 (13.38%) 659 (42.60%)                                                                                       60.57%         Medley with logistic regression    FALSE 305 (19.72%) 376 (24.31%)                                                      TRUE 175 (11.31%) 691 (44.67%)                                                                                       64.38%               Medley with random forest    FALSE 320 (20.69%) 361 (23.34%)                                                      TRUE 194 (12.54%) 672 (43.44%)                                                                                       64.12%"},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Jason Bryer. Author, maintainer.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Bryer J (2025). medley: Predictive Modeling Missing Data. R package version 0.9.2, https://github.com/jbryer/medley/.","code":"@Manual{,   title = {medley: Predictive Modeling with Missing Data},   author = {Jason Bryer},   year = {2025},   note = {R package version 0.9.2},   url = {https://github.com/jbryer/medley/}, }"},{"path":"/index.html","id":"id_-medley-predictive-modeling-with-missing-data","dir":"","previous_headings":"","what":"Predictive Modeling with Missing Data","title":"Predictive Modeling with Missing Data","text":"Author: Jason Bryer, Ph.D. jason@bryer.orgWebsite: https://jbryer.github.io/medley/ predictive modeling strategies require missing data model estimation. missing data, generally two strategies working missing data: 1.) exclude variables (columns) observations (rows) missing data; 2.) impute missing data. However, data often missing systematic ways. Excluding data training ignoring potentially predictive information many imputation procedures missing completely random (MCAR) assumption violated. medley package implements solution modeling systematic patterns missingness. working example predicting student retention larger study Diagnostic Assessment Achievement College Skills (DAACS) explored. study, demographic data collected enrollment students students completed diagnostic assessments self-regulated learning (SRL), writing, mathematics, reading first weeks semester. Although students expected complete DAACS, consequence therefore large percentage student completed none assessments. resulting dataset three predominate response patterns: 1.) students completed four assessments, 2.) students completed SRL assessment, 3). students complete assessments. goal medley algorithm take advantage missing data patterns. example, medley algorithm trained three predictive models: 1.) demographics plus four assessments, 2.) demographics plus SRL assessment, 3.) demographics . training prediction, model used student based upon data available. , student completed SRL, model 2 used. medley algorithm can used statistical models. study, logistic regression random forest used. accuracy medley algorithm 3.5% better using complete data 3.1% better using dataset missing data imputed using mice package. medley package provides approach predictive modeling using training prediction framework R users accustomed using. numerous parameters can modified including underlying statistical models used training. Additional diagnostic functions available explore missing data patterns.","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Predictive Modeling with Missing Data","text":"can install development version medley like :","code":"remotes::install_github('jbryer/medley')"},{"path":"/reference/calculate_roc.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the statistics for receiver operating characteristic curve — calculate_roc","title":"Calculate the statistics for receiver operating characteristic curve — calculate_roc","text":"function adapted Raffel (https://github.com/joyofdata): https://github.com/joyofdata/joyofdata-articles/blob/master/roc-auc/calculate_roc.R","code":""},{"path":"/reference/calculate_roc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the statistics for receiver operating characteristic curve — calculate_roc","text":"","code":"calculate_roc(predictions, observed, cost_of_fp = 1, cost_of_fn = 1, n = 100)  # S3 method for class 'roc' summary(object, digits = 3, ...)  # S3 method for class 'roc' plot(x, curve = \"accuracy\", legend.position = c(1, 0.2), ...)"},{"path":"/reference/calculate_roc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the statistics for receiver operating characteristic curve — calculate_roc","text":"predictions predicted values. observed actual observed outcomes. cost_of_fp cost false positive. cost_of_fn cost false negative. n number steps estimate. object result [calculate_roc()]. digits number digits print. ... currently unused. x result [calculate_roc()]. curve values can cost, accuracy, NULL. legend.position position legend teh accuracy curve plot.","code":""},{"path":"/reference/calculate_roc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the statistics for receiver operating characteristic curve — calculate_roc","text":"ggplot2 expression.","code":""},{"path":"/reference/combine_confusion_matrices.html","id":null,"dir":"Reference","previous_headings":"","what":"Combine multiple confusion matrices into a single table. — combine_confusion_matrices","title":"Combine multiple confusion matrices into a single table. — combine_confusion_matrices","text":"combine multiple confusion matrices single table ideal comparing performance across multiple models.","code":""},{"path":"/reference/combine_confusion_matrices.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Combine multiple confusion matrices into a single table. — combine_confusion_matrices","text":"","code":"combine_confusion_matrices(..., digits = 2)"},{"path":"/reference/combine_confusion_matrices.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Combine multiple confusion matrices into a single table. — combine_confusion_matrices","text":"... results [confusion_matrix()]. parameters named used row names matrix. digits number digits.","code":""},{"path":"/reference/confusion_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate a confusion matrix — confusion_matrix","title":"Calculate a confusion matrix — confusion_matrix","text":"Calculate confusion matrix","code":""},{"path":"/reference/confusion_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate a confusion matrix — confusion_matrix","text":"","code":"confusion_matrix(   observed,   predicted,   label_false = \"FALSE\",   label_true = \"TRUE\" )  # S3 method for class 'confusionmatrix' as.data.frame(x, row.names = NULL, optional = FALSE, digits = 2, ...)  # S3 method for class 'confusionmatrix' print(x, digits = 2, ...)"},{"path":"/reference/confusion_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate a confusion matrix — confusion_matrix","text":"observed vector observed values. vector either numeric vector 0s 1s logical. predicted vector predicted values. vector either numeric vector 0s 1s logical. label_false label FALSE values label_true label TRUE values. x result [confusion_matrix()]. row.names used. optional used. digits number decimal places print. ... currently used.","code":""},{"path":"/reference/confusion_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate a confusion matrix — confusion_matrix","text":"data.frame confusion matrix.","code":""},{"path":"/reference/confusion_matrix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate a confusion matrix — confusion_matrix","text":"","code":"observed <- c(rep(FALSE, 10), rep(TRUE, 2)) predicted <- rep(TRUE, 12) confusion_matrix(observed, predicted, label_true = 'Success', label_false = 'Failure') #>            predicted             #>   observed   Failure     Success #>    Failure 0 (0.00%) 10 (83.33%) #>    Success 0 (0.00%)  2 (16.67%) #> Accuracy: 16.67% #> Sensitivity: % #> Specificity: %"},{"path":"/reference/crosstab.html","id":null,"dir":"Reference","previous_headings":"","what":"Contingency and proportional table as a character — crosstab","title":"Contingency and proportional table as a character — crosstab","text":"wrapper [base::table()] [base::prop.table()] returns contingency proportional table single character string.","code":""},{"path":"/reference/crosstab.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Contingency and proportional table as a character — crosstab","text":"","code":"crosstab(x, digits = 2, useNA = \"ifany\", sep = \"; \")"},{"path":"/reference/crosstab.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Contingency and proportional table as a character — crosstab","text":"x factor. digits number digits proportions. useNA whether include NA values table. See details [base::table()]. sep separator categories.","code":""},{"path":"/reference/crosstab.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Contingency and proportional table as a character — crosstab","text":"character.","code":""},{"path":"/reference/crosstab.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Contingency and proportional table as a character — crosstab","text":"","code":"data(mtcars) crosstab(mtcars$am) #> [1] \"0: 19 (59.38%); 1: 13 (40.62%)\""},{"path":"/reference/daacs.html","id":null,"dir":"Reference","previous_headings":"","what":"Data from the Diagnostic Assessment and Achievement of College Skills (DAACS) — daacs","title":"Data from the Diagnostic Assessment and Achievement of College Skills (DAACS) — daacs","text":"data part larger randomized control trial designed test effect DAACS student success. data treatment group large online college. DAACS embedded within orientation. Although students expected complete orientation consequences . result DAACS data missing large proportion students.","code":""},{"path":"/reference/daacs.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Data from the Diagnostic Assessment and Achievement of College Skills (DAACS) — daacs","text":"data frame 5,154 observations 14 variables. retained whether student retained second semester srl student's self-regulated learning score math student's mathematics score reading student's reading score writing student's writing score income student's income level ordered factor employment student's employment status ell whether student English Language Learner ed_mother highest education level student's mother ed_father highest education level student's father ethnicity ethnicity student gender gender student military whether student active military age age student time enrollment page_views number feedback pages student viewed","code":""},{"path":"/reference/daacs.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Data from the Diagnostic Assessment and Achievement of College Skills (DAACS) — daacs","text":"https://daacs.net","code":""},{"path":"/reference/daacs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Data from the Diagnostic Assessment and Achievement of College Skills (DAACS) — daacs","text":"information DAACS, see https://daacs.net.","code":""},{"path":"/reference/downsample.html","id":null,"dir":"Reference","previous_headings":"","what":"Model training using downsampling. — downsample","title":"Model training using downsampling. — downsample","text":"Consider dataset 10--1 ratio class B dependent varaible. Assuming wish maintain 1--1 ratio model (can modified using `ratio` parameter), observation larger class (say ) randomly assigned number 1 10. example, 10 models estimated. Observations smaller class used every model observations larger class used one models. potentially advantageous since data used model.","code":""},{"path":"/reference/downsample.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Model training using downsampling. — downsample","text":"","code":"downsample(formu, data, model_fun, ratio = 1, show_progress = TRUE, ...)  # S3 method for class 'downsample' predict(object, newdata, ...)"},{"path":"/reference/downsample.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model training using downsampling. — downsample","text":"formu object class \"formula\" (one can coerced class): symbolic description model fitted. data data frame data estimate model . model_fun modeling function (e.g. `glm`). ratio ratio small class larger class downsampling. show_progress TRUE progress bar displayed showing status model estimations. ... parameters passed `model_fun`. object result [downsample()]. newdata optional data frame look variables predict. omitted, fitted values used.","code":""},{"path":"/reference/downsample.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Model training using downsampling. — downsample","text":"list model outputs, results `model_fun`.","code":""},{"path":"/reference/downsample.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Model training using downsampling. — downsample","text":"noted function simply wrapper prediction function long first parameter model formula second parameter data frame. `downsample` function pass parameters `model_fun` `...`. `predict` function return data frame row corresponds row training data frame `newdata` data frame columns predicted values trained models. Note `...` parameter passed appropriate `predict` function. example, models trained using `glm` logistic regression, passing `type = 'response'` provided predicted probabilities.","code":""},{"path":"/reference/downsample.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Model training using downsampling. — downsample","text":"","code":"data(\"pisa\", package = \"medley\") train_rows <- sample(nrow(pisa) * .7) pisa_train <- pisa[train_rows,] pisa_valid <- pisa[-train_rows,] pisa_ds_out <- downsample(     formu = Public ~ .,     data = pisa_train,     model_fun = glm,     ratio = 2,     family = binomial(link = 'logit') ) #>    |                                                                               |                                                                      |   0%   |                                                                               |==============                                                        |  20%   |                                                                               |============================                                          |  40%   |                                                                               |==========================================                            |  60%   |                                                                               |========================================================              |  80%   |                                                                               |======================================================================| 100% pisa_predictions_ds <- predict(pisa_ds_out, newdata = pisa_valid, type = 'response') pisa_predictions_ds2 <- pisa_predictions_ds |> apply(1, mean)"},{"path":"/reference/expand_formula.html","id":null,"dir":"Reference","previous_headings":"","what":"Utility function that will expand the formula if the independent variable(s) are not full specified. — expand_formula","title":"Utility function that will expand the formula if the independent variable(s) are not full specified. — expand_formula","text":"function add independent variables formula formula specified `y ~ .`.","code":""},{"path":"/reference/expand_formula.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Utility function that will expand the formula if the independent variable(s) are not full specified. — expand_formula","text":"","code":"expand_formula(formula, data)"},{"path":"/reference/expand_formula.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Utility function that will expand the formula if the independent variable(s) are not full specified. — expand_formula","text":"formula formula expand. data data.frame formula applied .","code":""},{"path":"/reference/expand_formula.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Utility function that will expand the formula if the independent variable(s) are not full specified. — expand_formula","text":"formula independent variables specified explicitly.","code":""},{"path":"/reference/get_variable_sets.html","id":null,"dir":"Reference","previous_headings":"","what":"Gets list of model formulas based upon the missing data pattern in the data set. — get_variable_sets","title":"Gets list of model formulas based upon the missing data pattern in the data set. — get_variable_sets","text":"Gets list model formulas based upon missing data pattern data set.","code":""},{"path":"/reference/get_variable_sets.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gets list of model formulas based upon the missing data pattern in the data set. — get_variable_sets","text":"","code":"get_variable_sets(data, formula, min_set_size = 0.1)  # S3 method for class 'variableset' print(x, ...)"},{"path":"/reference/get_variable_sets.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gets list of model formulas based upon the missing data pattern in the data set. — get_variable_sets","text":"data data.frame. formula formula includes possible variables consider predictive models. min_set_size minimum set size percentage include model. x results `get_variable_sets()`. ... currently unused.","code":""},{"path":"/reference/get_variable_sets.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gets list of model formulas based upon the missing data pattern in the data set. — get_variable_sets","text":"list formulas, order used, predictive models.","code":""},{"path":"/reference/medley_train.html","id":null,"dir":"Reference","previous_headings":"","what":"Train models using different combinations of predictor variables based upon missing data patterns. — medley_train","title":"Train models using different combinations of predictor variables based upon missing data patterns. — medley_train","text":"Train models using different combinations predictor variables based upon missing data patterns.","code":""},{"path":"/reference/medley_train.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Train models using different combinations of predictor variables based upon missing data patterns. — medley_train","text":"","code":"medley_train(   data,   formula,   method = glm,   var_sets = get_variable_sets(data = data, formula = formula, min_set_size =     min_set_size),   min_set_size = 0.1,   exclusive_membership = TRUE,   ... )  # S3 method for class 'medley' summary(object, ...)  # S3 method for class 'medley' print(x, ...)  # S3 method for class 'medley' predict(object, newdata, ...)"},{"path":"/reference/medley_train.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Train models using different combinations of predictor variables based upon missing data patterns. — medley_train","text":"data data.frame used estimate models. formula possible predictor varaibles considered. method function used train models (e.g. glm, randomForest). var_sets list formulas use predictive models. min_set_size minimum set size percentage incldue model. exclusive_membership whether observation used model predictor variables available. `FALSE` observations may used training one model. ... parameters passed `predict()` function. object results `medley_train`. x results `medley_train`. newdata (optional) new data.frame get predictions .","code":""},{"path":"/reference/medley_train.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Train models using different combinations of predictor variables based upon missing data patterns. — medley_train","text":"object following elements: n_models number models trained. formulas list formulas used train models. models list objects returned training method. data data.frame used train models. model_observations data.frame specifies observations used model(s). vector predictions.","code":""},{"path":"/reference/metrics.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the accuracy rate. — accuracy","title":"Calculate the accuracy rate. — accuracy","text":"function provides overall accuracy rate two vectors. sum true positive true negative values. sum(True positive) / sum(Condition positive) sum(True negative) / sum(Condition negative)","code":""},{"path":"/reference/metrics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the accuracy rate. — accuracy","text":"","code":"accuracy(observed, predicted)  sensitivity(observed, predicted)  specificity(observed, predicted)"},{"path":"/reference/metrics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the accuracy rate. — accuracy","text":"observed vector observed values. predicted vector predicted values.","code":""},{"path":"/reference/metrics.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the accuracy rate. — accuracy","text":"accuracy numeric value.","code":""},{"path":"/reference/nhis.html","id":null,"dir":"Reference","previous_headings":"","what":"National Health Interview Survey (NHIS) 2017 — nhis","title":"National Health Interview Survey (NHIS) 2017 — nhis","text":"National Health Interview Survey (NHIS) monitors health civilian non-institutionalized U.S. population collection analysis data broad range health topics.","code":""},{"path":"/reference/nhis.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"National Health Interview Survey (NHIS) 2017 — nhis","text":"data frame 26,742 observations 1,414 variables.","code":""},{"path":"/reference/nhis.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"National Health Interview Survey (NHIS) 2017 — nhis","text":"https://archive.cdc.gov/www_cdc_gov/nchs/nhis/nhis_2017_data_release.htm","code":""},{"path":"/reference/nhis.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"National Health Interview Survey (NHIS) 2017 — nhis","text":"dataset used Perez-Lebel (2022) paper Benchmarking missing-values approaches predictive models health databases.\" information available : https://github.com/aperezlebel/benchmark_mv_approaches","code":""},{"path":"/reference/pisa.html","id":null,"dir":"Reference","previous_headings":"","what":"Programme of International Student Assessment — pisa","title":"Programme of International Student Assessment — pisa","text":"data 2019 PISA implementation United States. used predict whether student attends public private school. dependent variable (`Public`) imbalanced approximately 93","code":""},{"path":"/reference/pisa.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Programme of International Student Assessment — pisa","text":"data frame 5,233 observations 45 variables. Public Whether student attends public private school. ST04Q01 Sex ST05Q01 Attend <ISCED 0> ST06Q01 Age <ISCED 1> ST07Q01 Repeat <ISCED 1> ST08Q01 Home - Mother ST08Q02 Home - Father ST08Q03 Home - Brothers ST08Q04 Home - Sisters ST08Q05 Home - Grandparents ST08Q06 Home - Others ST10Q01 Mother  <Highest Schooling> ST12Q01 Mother Current Job Status ST14Q01 Father  <Highest Schooling> ST16Q01 Father Current Job Status ST19Q01 Language home ST20Q01 Possessions desk ST20Q02 Possessions room ST20Q03 Possessions study place ST20Q04 Possessions  computer ST20Q05 Possessions software ST20Q06 Possessions Internet ST20Q07 Possessions literature ST20Q08 Possessions poetry ST20Q09 Possessions art ST20Q10 Possessions textbooks ST20Q12 Possessions dictionary ST20Q13 Possessions dishwasher ST21Q01 many cellular phones ST21Q02 many televisions ST21Q03 many computers ST21Q04 many cars ST21Q05 many rooms bath shower ST22Q01 many books home ST23Q01 Reading Enjoyment Time ST31Q01 <Enrich> <test lang> ST31Q02 <Enrich> <mathematics> ST31Q03 <Enrich> <science> ST31Q05 <Remedial> <test lang> ST31Q06 <Remedial> <mathematics> ST31Q07 <Remedial> <science> ST32Q01 school lessons <test lang> ST32Q02 school lessons <maths> ST32Q03 school lessons <science>","code":""},{"path":"/reference/pisa.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Programme of International Student Assessment — pisa","text":"https://www.pisa.oecd.org","code":""},{"path":"/reference/pisa.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Programme of International Student Assessment — pisa","text":"dataset modified original data provided OECD. [`pisa`](https://github.com/jbryer/pisa) R package Github provides complete data 2019 administration.","code":""},{"path":"/reference/pisa_variables.html","id":null,"dir":"Reference","previous_headings":"","what":"Programme of International Student Assessment — pisa_variables","title":"Programme of International Student Assessment — pisa_variables","text":"character vector names variables correspond variables names `pisa` data frame values descriptions variables.","code":""},{"path":"/reference/pisa_variables.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Programme of International Student Assessment — pisa_variables","text":"character vector.","code":""},{"path":"/reference/pisa_variables.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Programme of International Student Assessment — pisa_variables","text":"https://www.pisa.oecd.org","code":""},{"path":"/reference/recode_small_levels.html","id":null,"dir":"Reference","previous_headings":"","what":"Recode levels of a factor that are below a given threshold. — recode_small_levels","title":"Recode levels of a factor that are below a given threshold. — recode_small_levels","text":"function first calculate contingency table. categories specified `threshold`, raw values `x` recoded. default `NA`, can specified `recode_to` parameter. resulting vector converted factor using `factor()` function.","code":""},{"path":"/reference/recode_small_levels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Recode levels of a factor that are below a given threshold. — recode_small_levels","text":"","code":"recode_small_levels(x, recode_to = NA, threshold = length(x) * 0.01, ...)"},{"path":"/reference/recode_small_levels.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Recode levels of a factor that are below a given threshold. — recode_small_levels","text":"x vector. recode_to value recode small factor levels . threshold threshold factor level count recoded. ... parameters passed `factor()`.","code":""},{"path":"/reference/recode_small_levels.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Recode levels of a factor that are below a given threshold. — recode_small_levels","text":"recoded factor. result factor regardless type `x`.","code":""},{"path":"/reference/recode_small_levels.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Recode levels of a factor that are below a given threshold. — recode_small_levels","text":"","code":"data(mtacars) #> Warning: data set ‘mtacars’ not found table(mtcars$carb) #>  #>  1  2  3  4  6  8  #>  7 10  3 10  1  1  cbind(mtcars$carb, medley::recode_small_levels(mtcars$carb, threshold = 2)) #>       [,1] [,2] #>  [1,]    4    4 #>  [2,]    4    4 #>  [3,]    1    1 #>  [4,]    1    1 #>  [5,]    2    2 #>  [6,]    1    1 #>  [7,]    4    4 #>  [8,]    2    2 #>  [9,]    2    2 #> [10,]    4    4 #> [11,]    4    4 #> [12,]    3    3 #> [13,]    3    3 #> [14,]    3    3 #> [15,]    4    4 #> [16,]    4    4 #> [17,]    4    4 #> [18,]    1    1 #> [19,]    2    2 #> [20,]    1    1 #> [21,]    1    1 #> [22,]    2    2 #> [23,]    2    2 #> [24,]    4    4 #> [25,]    2    2 #> [26,]    1    1 #> [27,]    2    2 #> [28,]    2    2 #> [29,]    4    4 #> [30,]    6   NA #> [31,]    8   NA #> [32,]    2    2"}]
